{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc36d58",
   "metadata": {},
   "source": [
    "# C4 metacalibration on cluster injections\n",
    "\n",
    "\n",
    "In this notebook we will finally connect the dots, and apply the metacalibration algorithm to estimate the shear field around a galaxy cluster injected into the DC2 simulation.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "    1 Use the metacalibration algorithm in the cluster lensing scenario\n",
    "\n",
    "    2 Measure the tangential shear field induced by a galaxy cluster\n",
    "   \n",
    "\n",
    "## Setup\n",
    "\n",
    "This notebook relies on the:\n",
    "\n",
    "    * synthetic package & dependencies\n",
    "    \n",
    "    * DC2 cutotut data files on disk\n",
    "    \n",
    "    * curated galaxy cluster member catalog (see A4 notebook)\n",
    "       \n",
    "\n",
    "\n",
    "## Output\n",
    "\n",
    "    * tangential shear profile input vs measured for a galaxy cluster\n",
    "    \n",
    "    \n",
    "The output files are placed in the `./data/` folder\n",
    "\n",
    "\n",
    "## Contact\n",
    "\n",
    "In case of questions, contact me at t.varga@physik.lmu.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae46821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio as fio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import astropy.cosmology as cosmology\n",
    "\n",
    "import images # package from erin sheldon\n",
    "\n",
    "import synthetic.tools as tools\n",
    "import synthetic.render.frame as frame\n",
    "import synthetic.render.render as render\n",
    "import synthetic.render.icl as icl\n",
    "\n",
    "import galsim\n",
    "import images # package from erin sheldon\n",
    "\n",
    "import meds\n",
    "import psfex # The python wrapper\n",
    "\n",
    "pixel_scale = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6bc943",
   "metadata": {},
   "source": [
    "*** Important *** set the `nprocess` value to the amount of CPU cores you are willing or allowed to use for this notebook\n",
    "\n",
    "please consider your local server, e.g. don't run heavy calculations on public login nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7342ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nprocess = 4\n",
    "nprocess = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480ce5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output path for mock image, be sure to place it into a folder where you can write a few GBs of files \n",
    "out_path = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f60db",
   "metadata": {},
   "source": [
    "# Prepare the cluster injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8a877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = './data/refdata/curated_table.h5'\n",
    "table = pd.read_hdf(table_path, key=\"data\")\n",
    "\n",
    "ra_cen = 50.64516228577292\n",
    "dec_cen = -40.228830895890404\n",
    "\n",
    "mock_catalog_path = './data/refdata/curated_mock_catalog.h5'\n",
    "mock_catalog = pd.read_hdf(mock_catalog_path, key=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8a953",
   "metadata": {},
   "source": [
    "## Create a shear profile\n",
    "\n",
    "For illustration purposes, we are going to use an isothermal (power law) shear profile\n",
    "\n",
    "In case you have other preferences, the below section is where you must modify the line-of-sight catalog\n",
    "\n",
    "You can add magnification, or other shear profiles as your preferences dictate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4649c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = cosmology.FlatLambdaCDM(Om0=0.3, H0=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7234ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_offset=(2499.5, 2499.5)\n",
    "\n",
    "xra = (mock_catalog['X'] - image_offset[0]) * pixel_scale / 60 # arcmin\n",
    "ydec = (mock_catalog['Y'] - image_offset[1]) * pixel_scale / 60 # arcmin\n",
    "dists = np.sqrt(xra**2 + ydec**2)\n",
    "\n",
    "shears = np.sqrt(1 / dists  / 400) # just for illustration purposes\n",
    "shears[shears > 0.8] = 0.8 # galsim cannot render very large shears properly\n",
    "\n",
    "phis =  np.arctan2(ydec, xra)\n",
    "es1 = (-1. * shears * np.cos(2 * phis))\n",
    "es2 = (-1. * shears * np.sin(2 * phis))\n",
    "\n",
    "\n",
    "e1 = mock_catalog['G1']\n",
    "e2 = mock_catalog['G2']\n",
    "vals1 = e1 + es1 - e1 * es1 - e2 * es2 # Calculate the sheared galaxy shape\n",
    "vals2 = e2 + es2 - es1 * e2 + es2 * e1\n",
    "\n",
    "tmp = np.sqrt(vals1**2. + vals2**2.)\n",
    "ii = tmp > 0.9 # galsim cannot render very large shears properly, we must reduce the \n",
    "divs = 1. / (0.1 + tmp[ii])  \n",
    "vals1[ii] *= divs\n",
    "vals2[ii] *= divs\n",
    "\n",
    "# Add shear only to galaxies, which are at z > 0.4,\n",
    "# this is a super simple approximation, intended to showcase the functionality\n",
    "jj = table['redshift_true'] > 0.4\n",
    "\n",
    "mock_catalog.loc[jj, \"G1\"] = vals1[jj]\n",
    "mock_catalog.loc[jj, \"G2\"] = vals2[jj]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacee58",
   "metadata": {},
   "source": [
    "## Render cluster injection\n",
    "\n",
    "For this example, we are going to use a curated galaxy cluster member catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51bbe772",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cluster_path = './data/refdata/curated_cluster_model_v01-z0l0_15000_001.h5'\n",
    "mock_cluster = pd.read_hdf(mock_cluster_path, key=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704252e",
   "metadata": {},
   "source": [
    "For this example, this is saved in the same database format (exact same columns) as the DC2 catalog which we used above, so we can simply concatenate them in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060441ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_all = pd.concat((mock_cluster, mock_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4a646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test_cluster_canvas_dc2_g\n",
      "starting postage stamp calculations in 1 processes\n",
      "./data/test_cluster_canvas_dc2_r\n",
      "starting postage stamp calculations in 1 processes\n"
     ]
    }
   ],
   "source": [
    "# These are the approcimate noise levels we are going to use for mock images in this notebook\n",
    "# g, r, i, z bands\n",
    "stds = np.array([2.509813, 5.192254, 8.36335, 15.220351]) / 1.3\n",
    "\n",
    "# This is the file name root, appended by bands\n",
    "# we render only g, r, i as those already make a nice color image\n",
    "file_name_tag = 'test_cluster_canvas_dc2_' #\n",
    "\n",
    "for i, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "    name = out_path + file_name_tag + band\n",
    "    print(name)\n",
    "    fr = frame.Frame(mock_all.to_records(), band=band, name=name,\n",
    "                     center=(ra_cen, dec_cen), noise_std=stds[i], canvas_size=5000)\n",
    "    fr.render(nprocess=nprocess) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50317b",
   "metadata": {},
   "source": [
    "## Create intra-cluster-light image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540498b",
   "metadata": {},
   "source": [
    "We are creating the ICL as a separate 2D array, for each pixel of the observation canvas. So that it can be manipulated as an image, added directly to the rendered galaxy catalogs. \n",
    "\n",
    "This way an arbitrary light profile can be added. In the following we are going to use the approach and codebase derived from Varga et al 2021, based on the parametrization of Gruen et al 2019, using the intra cluster light measurements of Zhang et al 2019.\n",
    "\n",
    "In this approach, a doughnut shaped pseudo ICL model is calculated, which is the real ICL light profile from which the core Elliptical galaxy is subtracted out, so that the sum of the two components will agree with the observed light distribution.\n",
    "\n",
    "We should note that the ICL can have an ellipticity in this model, for now simply taken as the orientation of the BCG.\n",
    "\n",
    "***Right now we are going to place an intra cluster light profile centered around the center of the canvas!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "galpath = \"./data/refdata/ICL/evolving_red_gal.dat\"\n",
    "mstarpath = \"./data/refdata/ICL/mstar_des_i03.fit\"\n",
    "jk_profile_root = \"./data/refdata/ICL/jacknife_profiles_0.15_rand_back_subtracted_corZ_faintgalsub/jacknife_profile_\"\n",
    "\n",
    "bcg = {\n",
    "    \"size\": 32.,\n",
    "    \"g1\": -0.1356766444194723,\n",
    "    \"g2\":0.0345231539560347,\n",
    "    \"imag\": 17.76, # i band magnitude\n",
    "    \"color_gr\": 1.36,\n",
    "    \"color_ri\": 0.54,\n",
    "    \"color_iz\": 0.32,\n",
    "}\n",
    "mass = 10**14.45 # in solar masses\n",
    "z = 0.3 # cluster redshift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = icl.DrawICL(mass, z, bcg, galpath, mstarpath, jk_profile_root)\n",
    "di.get_icl()\n",
    "ims_icl = [di.flux_g, di.flux_r, di.flux_i, di.flux_z]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a2298",
   "metadata": {},
   "source": [
    "then we load the pre icl images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_all = []\n",
    "for i, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "    name = out_path + 'test_cluster_canvas_dc2_' + band + \".fits\"\n",
    "    tmp = fio.read(name)\n",
    "    print(name)\n",
    "    ims_all.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d705750",
   "metadata": {},
   "source": [
    "So that we can simply add the two components together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc82cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "ax = axarr[0]\n",
    "factor = 0.01\n",
    "scales = np.array([1., 1.2, 2.5]) * factor\n",
    "nonlinear = 0.12\n",
    "clip = 0\n",
    "\n",
    "pad = 0\n",
    "obs_im = images.get_color_image(ims_all[2] + pad,\n",
    "                                ims_all[1] + pad,\n",
    "                                ims_all[0] + pad,\n",
    "                                nonlinear=nonlinear, clip=clip, scales=scales)  \n",
    "print(obs_im.max())\n",
    "ax.imshow(obs_im[2400:2600, 2400:2600] * 2, origin='upper')\n",
    "\n",
    "ax.set_title(\"cluster + field \")\n",
    "\n",
    "ax.set_xlabel(\"X [pix]\")\n",
    "ax.set_ylabel(\"Y [pix]\")\n",
    "\n",
    "ax = axarr[1]\n",
    "factor = 0.01\n",
    "scales = np.array([1., 1.2, 2.5]) * factor\n",
    "nonlinear = 0.12\n",
    "clip = 0\n",
    "\n",
    "pad = 0\n",
    "obs_im = images.get_color_image(ims_all[2] + ims_icl[2] + pad,\n",
    "                                ims_all[1] + ims_icl[1] + pad,\n",
    "                                ims_all[0] + ims_icl[0] + pad,\n",
    "                                nonlinear=nonlinear, clip=clip, scales=scales)  \n",
    "print(obs_im.max())\n",
    "ax.imshow(obs_im[2400:2600, 2400:2600] * 2, origin='upper')\n",
    "\n",
    "ax.set_title(\"cluster + field + ICL added\")\n",
    "\n",
    "ax.set_xlabel(\"X [pix]\")\n",
    "ax.set_ylabel(\"Y [pix]\")\n",
    "\n",
    "fig.savefig(\"./data/dc2_hp_icl_panel.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6c7e2",
   "metadata": {},
   "source": [
    "## Creating a deeper, detection image and weight map\n",
    "\n",
    "source detection is traditionally done on coadded images, even when shear estimation is performed per-frame for greater performance.\n",
    "\n",
    "For this reason, unlike in B1, B2, B3, we are going to create a single, deeper, detection frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e905074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_canvas_i\n",
      "starting postage stamp calculations in 100 processes\n"
     ]
    }
   ],
   "source": [
    "band = 'i'\n",
    "name = out_path + 'test_canvas_' + band\n",
    "print(name)\n",
    "fr = frame.Frame(mock_catalog.to_records(), band=band, name=name,\n",
    "                     center=(ra_cen, dec_cen), noise_std=1., canvas_size=5000, config_se='data/configs/config.sex')\n",
    "fr.render() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0cc7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.ones(shape=(fr.canvas_size, fr.canvas_size)) # this is set as 1, as in this example that's the noise std\n",
    "wcanvas = galsim.ImageF(noise, wcs=fr.canvas.wcs)\n",
    "wcanvas.write(name + '_weight.fits', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.extract()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
