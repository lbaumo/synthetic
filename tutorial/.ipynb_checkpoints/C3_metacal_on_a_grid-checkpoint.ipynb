{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc36d58",
   "metadata": {},
   "source": [
    "# C3 metacalibration on a grid\n",
    "\n",
    "\n",
    "In this notebook we process the rendered galaxy catalogs using the sextractor software, and transport them into a multi-epoch data system, which will later be used to interface with metacalibration\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "    1 run a minimal version of metacalibration\n",
    "    \n",
    "    2 recover constant shear from a grid of postage stamps\n",
    " \n",
    "\n",
    "**TODO** Check the weight map, with someone expert\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "This notebook relies on the:\n",
    "\n",
    "    * synthetic package & dependencies\n",
    "    \n",
    "    * prepared & curated DC2 cutout data file\n",
    "\n",
    "\n",
    "## Output\n",
    "\n",
    "    * Recovered constant shear :)\n",
    "    \n",
    "The output files are placed in the `./data/` folder\n",
    "\n",
    "\n",
    "## Contact\n",
    "\n",
    "In case of questions, contact me at t.varga@physik.lmu.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae46821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio as fio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import galsim\n",
    "import astropy.cosmology as cosmology\n",
    "\n",
    "import images # package from erin sheldon\n",
    "\n",
    "import synthetic.tools as tools\n",
    "import synthetic.render.frame as frame\n",
    "import synthetic.render.render as render\n",
    "import synthetic.mcal as mcal\n",
    "\n",
    "\n",
    "import meds\n",
    "import psfex # The python wrapper\n",
    "\n",
    "pixel_scale = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f60db",
   "metadata": {},
   "source": [
    "# Create a rendered image we are going to work on\n",
    "\n",
    "and run source extractor\n",
    "\n",
    "This part reproduces where largely identical to the B2 left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c6ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for input DC2 files\n",
    "in_path = \"/e/ocean1/users/vargatn/LSST/DC2_1.1.4/\" \n",
    "# output path for mock image, be sure to place it into \n",
    "out_path = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f942f31",
   "metadata": {},
   "source": [
    "Now we make a grid of roughly similar galaxies. They are defined in a similar parameter space as teh mock catalogs in the B1, B2 notebooks\n",
    "\n",
    "We will add a constant amount of e1, e2 shear into this image to each galaxy, and then aim to recover it with the metacalibration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc1038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shear1 = 0.02\n",
    "shear2 = -0.01\n",
    "\n",
    "shape_std=0.2  # shape noise of the mock galaxy catalog\n",
    "\n",
    "ra_cen = 50.64516228577292 # RA center of mock pointing [deg]\n",
    "dec_cen = -40.228830895890404 # DEC center of mock pointing [deg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48afc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23000)\n",
    "\n",
    "\n",
    "nobjects = 10000\n",
    "canvas_size = 10000\n",
    "padding = 100\n",
    "mock_catalog = pd.DataFrame()\n",
    "\n",
    "\n",
    "x = np.linspace(padding, canvas_size - padding, 100)\n",
    "y = np.linspace(padding, canvas_size - padding, 100)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "xx = xx.flatten()\n",
    "yy = yy.flatten()\n",
    "\n",
    "\n",
    "# this is something of an artifact, the X, Y is starting at 0, not at the image center... might need to be fixed\n",
    "mock_catalog[\"X\"] = xx\n",
    "mock_catalog[\"Y\"] = yy\n",
    "# lsizes = np.random.normal(loc=0.4, scale=0.1, size=nobjects)\n",
    "mock_catalog[\"TSIZE\"] = 6 \n",
    "mock_catalog[\"FRACDEV\"] = 1 #np.random.uniform(0, 1, size=nobjects)\n",
    "mock_catalog[\"MAG_I\"] = 21 #np.random.normal(loc=22, scale=0.5, size=nobjects)\n",
    "mock_catalog[\"FLUX_I\"] = tools.toflux(mock_catalog[\"MAG_I\"])\n",
    "mock_catalog[\"G1\"] = np.random.normal(loc=0, scale=shape_std, size=nobjects) + shear1\n",
    "mock_catalog[\"G2\"] = np.random.normal(loc=0, scale=shape_std, size=nobjects) + shear2\n",
    "\n",
    "g1 = mock_catalog[\"G1\"]\n",
    "g2 = mock_catalog[\"G2\"]\n",
    "amp = np.sqrt(g1**2 + g2**2) \n",
    "\n",
    "ii = amp > 0.8\n",
    "mock_catalog.loc[ii, 'G1'] *= 0.8 / amp[ii]\n",
    "mock_catalog.loc[ii, 'G2'] *= 0.8 / amp[ii]\n",
    "\n",
    "# amp = np.sqrt(g1**2 + g2**2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbf7b4",
   "metadata": {},
   "source": [
    "# Preparing the grid of postage stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdfa17",
   "metadata": {},
   "source": [
    "## Creating a deeper, detection image and weight map\n",
    "\n",
    "source detection is traditionally done on coadded images, even when shear estimation is performed per-frame for greater performance.\n",
    "\n",
    "For this reason, unlike in B1, B2, B3, we are going to create a single, deeper, detection frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_canvas_i\n",
      "starting postage stamp calculations in 100 processes\n"
     ]
    }
   ],
   "source": [
    "band = 'i'\n",
    "name = out_path + 'test_canvas_' + band\n",
    "print(name)\n",
    "fr = frame.Frame(mock_catalog.to_records(), band=band, name=name,\n",
    "                     center=(ra_cen, dec_cen), noise_std=1., canvas_size=canvas_size, config_se='data/configs/config.sex')\n",
    "fr.render() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8a8e6",
   "metadata": {},
   "source": [
    "we also have to create a weight map\n",
    "\n",
    "**TODO** check the actual values for this!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.ones(shape=(fr.canvas_size, fr.canvas_size)) # this is set as 1, as in this example that's the noise std\n",
    "wcanvas = galsim.ImageF(noise, wcs=fr.canvas.wcs)\n",
    "wcanvas.write(name + '_weight.fits', clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff7f90",
   "metadata": {},
   "source": [
    "after rendering, we can run sextractor, and load the results as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febcf44",
   "metadata": {},
   "source": [
    "here we have access to the sextractor catalog, and the segmentation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = fr.scat.copy()\n",
    "seg = fio.read(\"data/test_canvas_i_seg.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c436be",
   "metadata": {},
   "source": [
    "before we go further, let's see the grid of galaxy postage stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "arr = fr.canvas.array[2000:3000, 3000:4000]\n",
    "ax.imshow(np.arcsinh(arr) / arr, cmap=plt.cm.gray)\n",
    "ax.set_xlabel(\"X [pix]\")\n",
    "ax.set_ylabel(\"Y [pix]\")\n",
    "ax.set_title('random 1k x 1k pixel cutout of a larger galaxy grid, not centered')\n",
    "fig.savefig(\"data/grid_illustration.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879b597",
   "metadata": {},
   "source": [
    "## Creating a multi epoch data system file (MEDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168a246",
   "metadata": {},
   "source": [
    "See the C2 notebook\n",
    "\n",
    "Now we are going to transform the synthetic image, into the multi epoch data system format, which is the last step before we can run metacalibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = fr.scat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimage = 1 # one exposure per object, we are simulating coadds with identical observational conditions\n",
    "nobj = len(objects)\n",
    "obj_data = meds.util.get_meds_input_struct(nobj, extra_fields=[(\"X_IMAGE\", \"f8\"), (\"Y_IMAGE\", \"f8\")])\n",
    "obj_data['id'] = objects['NUMBER'] # the source extractor ID, starts with 1, not 0...\n",
    "\n",
    "# This the size of the bounding box for the object, should be adaptive based on the size of the source\n",
    "box_sizes = np.round(objects[\"A_IMAGE\"] * objects[\"B_IMAGE\"] * 2 ) *2\n",
    "box_sizes[box_sizes < 16] = 16 \n",
    "obj_data['box_size'] = box_sizes\n",
    "\n",
    "# The below are the positions of the source on the sky and in the image-\n",
    "# The actual MEDS script uses the sky position based on the image WCS, but this is done completely under the hood\n",
    "obj_data['ra'] = objects['ALPHAWIN_J2000'] + pixel_scale / 3600 # this is a hack for fortran vs python ordered arrays\n",
    "obj_data['dec'] = objects['DELTAWIN_J2000'] - pixel_scale / 3600 # this is a hack for fortran vs python ordered arrays\n",
    "obj_data['X_IMAGE'] = objects['X_IMAGE']\n",
    "obj_data['Y_IMAGE'] = objects['Y_IMAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822dcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = fr.name + \".fits\"\n",
    "path_weight = fr.name + \"_weight.fits\"\n",
    "path_seg = fr.name + \"_seg.fits\"\n",
    "\n",
    "# Due to some memory reservation issues, we have to tell expicitely how long the longest filename will be.\n",
    "path_length= np.max((len(path_image), len(path_seg), len(path_weight)))\n",
    "\n",
    "image_info= meds.util.get_image_info_struct(nimage, path_length)\n",
    "\n",
    "image_info['image_path'][0] = path_image\n",
    "image_info['weight_path'][0] = path_weight\n",
    "image_info['seg_path'][0] = path_seg\n",
    "image_info['magzp'] = 30.\n",
    "\n",
    "config = {'first_image_is_coadd': False,'cutout_types':['weight', 'seg'],'psf_type':'psfex'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4baf8c",
   "metadata": {},
   "source": [
    "Since this is a synthetic image, we know the exact PSF, \n",
    "\n",
    "In reality this was estimated from a grid of stars in the same pipeline, however that is out of scope for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pex = psfex.PSFEx(\"/e/ocean1/users/vargatn/LSST/SYNTHETIC/star_canvas_cat.psf\")\n",
    "psf_data = [pex,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5c2af",
   "metadata": {},
   "source": [
    "now all is set for running the MEDSMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637cfc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = meds.MEDSMaker(obj_data=obj_data, image_info=image_info, config=config, psf_data=psf_data)\n",
    "mm.write(out_path + \"grid.meds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aec549",
   "metadata": {},
   "source": [
    "now let's inspect the meds files, if all goes well, there should be a galaxy in each postage stamp cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = meds.MEDS(out_path + \"grid.meds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=6, nrows=6, figsize=(12,12))\n",
    "# fig.subplots_adjust(wspace=0.01)\n",
    "for i, ax in enumerate(axarr.flatten()):\n",
    "    im = m.get_cutout(i, 0, 'image')\n",
    "    ax.imshow(im)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])    \n",
    "fig.savefig(\"data/grid_illustration_meds.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7900dfb",
   "metadata": {},
   "source": [
    "# Running metacalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = out_path + \"grid.meds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41011273",
   "metadata": {},
   "source": [
    "we have to prepare a set of instructions for the metacal runner\n",
    "\n",
    "The actual calculation is split up to jobs, each processing a set of independent postage stamps, and the results are written to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6992f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest number of  objects to include from the sextractor detection catalog. \n",
    "maxnum = 40000 # for the example, you might be better off reducing the number from 10k down to fewer galaxies.\n",
    "\n",
    "nprocess = 100 # the number of OpenMP processes you want to / are allowed to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb898ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_names = out_path + \"grid_mcal\" # file name root of output (will have additional _01 _02 etc appended to it)\n",
    "\n",
    "infodicts = mcal.infomaker(maxnum, input_name, outfile_names, nchunk=nprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcal.multi_mcal(infodicts, nprocess=nprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a3fa4",
   "metadata": {},
   "source": [
    "now we need to read in the results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = mcal.collater(infodicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bda314",
   "metadata": {},
   "outputs": [],
   "source": [
    "gest1_raw =tab[\"g_noshear\"][:, 0].mean()\n",
    "gest2_raw =tab[\"g_noshear\"][:, 1].mean()\n",
    "\n",
    "gest1 =tab[\"g_noshear\"][:, 0].mean() / tab['r11'].mean()\n",
    "gest2 =tab[\"g_noshear\"][:, 1].mean() / tab['r22'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the measured shape  <e> with\",maxnum ,\"galaxies\")\n",
    "print(\"g1 = {:.4f}\".format(gest1_raw), \"the input shape is\", shear1)\n",
    "print(\"g2 = {:.4f}\".format(gest2_raw), \"the input shape is\", shear2)\n",
    "print('')\n",
    "print('METACALIBRATION:')\n",
    "print(\"the measured shape  <e> / <R> with\",maxnum ,\"galaxies\")\n",
    "print(\"g1 = {:.4f}\".format(gest1), \"the input shape is\", shear1)\n",
    "print(\"g2 = {:.4f}\".format(gest2), \"the input shape is\", shear2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b98cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab[\"g1_MC\"].mean() / tab['r11'].mean())\n",
    "# print(tab[\"g2_MC\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efebf88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
